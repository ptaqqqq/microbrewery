{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9773ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import gc\n",
    "from peft import LoraConfig, TaskType\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "import trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3cbb2330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['completion', 'prompt'],\n",
      "    num_rows: 51\n",
      "})\n",
      "{'completion': [{'content': 'Odpowiadaj krótko i konwersacyjnie :)', 'role': 'system'}, {'content': 'Jak mogę pomóc?', 'role': 'user'}, {'content': 'Jestem tutaj, aby pomóc. Jeśli masz jakieś pytania lub potrzebujesz wsparcia, śmiało pytaj!', 'role': 'assistant'}], 'prompt': [{'content': 'Odpowiadaj krótko i konwersacyjnie :)', 'role': 'system'}, {'content': 'Jak mogę pomóc?', 'role': 'user'}]}\n",
      "Dataset({\n",
      "    features: ['completion', 'prompt'],\n",
      "    num_rows: 13\n",
      "})\n",
      "{'completion': [{'content': 'Odpowiadaj krótko i konwersacyjnie :)', 'role': 'system'}, {'content': 'Jak działa sieć neuronowa?', 'role': 'user'}, {'content': 'Sieć neuronowa to model matematyczny inspirowany strukturą i funkcjami biologicznych neuronów.', 'role': 'assistant'}], 'prompt': [{'content': 'Odpowiadaj krótko i konwersacyjnie :)', 'role': 'system'}, {'content': 'Jak działa sieć neuronowa?', 'role': 'user'}]}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files={\"train\": \"./train.json\", \"test\": \"./test.json\"})\n",
    "\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "print(train_dataset)\n",
    "print(train_dataset[0])\n",
    "print(test_dataset)\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ffe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakub/Coding/30 - Personal projects/Self-reflect MiniGPT/.venv/lib/python3.13/site-packages/peft/tuners/lora/layer.py:1803: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.089400</td>\n",
       "      <td>6.314740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.844700</td>\n",
       "      <td>6.020119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>6.609700</td>\n",
       "      <td>5.909581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakub/Coding/30 - Personal projects/Self-reflect MiniGPT/.venv/lib/python3.13/site-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=35, training_loss=6.809966278076172, metrics={'train_runtime': 6.2618, 'train_samples_per_second': 40.723, 'train_steps_per_second': 5.589, 'total_flos': 9926068027392.0, 'train_loss': 6.809966278076172})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sdadas/polish-gpt2-small\")\n",
    "bielik_tokenizer = AutoTokenizer.from_pretrained(\"speakleash/Bielik-1.5B-v3.0-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"sdadas/polish-gpt2-small\")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"c_attn\", \"c_fc\", \"c_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM \n",
    ")\n",
    "\n",
    "trl.clone_chat_template(model, tokenizer, source_tokenizer_path=\"speakleash/Bielik-1.5B-v3.0-Instruct\")\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"student_model\",\n",
    "    max_length=512,\n",
    "    assistant_only_loss=True,\n",
    "    completion_only_loss=True,\n",
    "    per_device_train_batch_size=8, \n",
    "    gradient_accumulation_steps=1,\n",
    "    remove_unused_columns=False,\n",
    "    learning_rate=1e-5,\n",
    "    eval_strategy=\"steps\",\n",
    "    num_train_epochs=5\n",
    "\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    peft_config=lora_config\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4713f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:51201 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'completion': [{'content': 'Odpowiadaj krótko i konwersacyjnie :)', 'role': 'system'}, {'content': 'Jak działa sieć neuronowa?', 'role': 'user'}, {'content': 'Sieć neuronowa to model matematyczny inspirowany strukturą i funkcjami biologicznych neuronów.', 'role': 'assistant'}], 'prompt': [{'content': 'Odpowiadaj krótko i konwersacyjnie :)', 'role': 'system'}, {'content': 'Jak działa sieć neuronowa?', 'role': 'user'}]}\n",
      "tensor([[    0, 51200, 22283,   203, 16503,    78,  5879,   292, 36004,  6175,\n",
      "          7908, 51201,   203, 51200,    89,  1446,   203,   880,   878, 11770,\n",
      "         10938,  3385,    35, 51201,   203, 51200,   400,   393,  1111,    88,\n",
      "           203]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s><|im_start|>system\\nOdpowiadaj krótko i konwersacyjnie :)<|im_end|>\\n<|im_start|>user\\nJak działa sieć neuronowa?<|im_end|>\\n<|im_start|>assistant\\n.</s>W tym roku w Polsce jest ponad 1,5 mln osób, które nie ukończyły 18'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(test_dataset[0])\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "out = tokenizer.apply_chat_template(test_dataset[0][\"prompt\"], add_generation_prompt=True, return_tensors=\"pt\").to(DEVICE)\n",
    "print(out)\n",
    "tokenizer.decode(model.generate(out)[0], pad_token_id=tokenizer.eos_token_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
