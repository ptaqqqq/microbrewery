{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0241c3f",
   "metadata": {},
   "source": [
    "# Train student model on the generated dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c443cff9",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e81ece2",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540971fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import gc\n",
    "from peft import LoraConfig, TaskType\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "import trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b009dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f09020",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbb2330",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"json\", data_files={\"train\": \"./train.json\", \"test\": \"./test.json\"})\n",
    "\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "print(train_dataset)\n",
    "print(train_dataset[0])\n",
    "print(test_dataset)\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7863cee7",
   "metadata": {},
   "source": [
    "### Instantiate model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ffe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"sdadas/polish-gpt2-small\").to(DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sdadas/polish-gpt2-small\")\n",
    "tokenizer_bielik = AutoTokenizer.from_pretrained(\"speakleash/Bielik-1.5B-v3.0-Instruct\")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"c_attn\", \"c_fc\", \"c_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM \n",
    ")\n",
    "\n",
    "trl.clone_chat_template(model, tokenizer, source_tokenizer_path=\"speakleash/Bielik-1.5B-v3.0-Instruct\")\n",
    "\n",
    "tokenizer.eos_token_id = tokenizer.encode(\"</s>\")[0]\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780334d2",
   "metadata": {},
   "source": [
    "## Train and generate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8157ff3",
   "metadata": {},
   "source": [
    "### Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4713f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample_idx = 0\n",
    "\n",
    "def generate_from_prompt(prompt):\n",
    "    inputs = tokenizer.apply_chat_template(prompt, add_generation_prompt=True, return_tensors=\"pt\").to(DEVICE)\n",
    "    out_ids = model.generate(\n",
    "        input_ids=inputs,\n",
    "        max_new_tokens=128,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.2,\n",
    "        no_repeat_ngram_size=3,\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    sequence = out_ids[0].tolist()\n",
    "    print(tokenizer.decode(tokenizer.eos_token_id))\n",
    "    if tokenizer.eos_token_id in sequence:\n",
    "        cut_at = sequence.index(tokenizer.eos_token_id)\n",
    "        sequence = sequence[:cut_at+1]\n",
    "\n",
    "    return tokenizer.decode(sequence)\n",
    "\n",
    "generate_from_prompt(test_dataset[test_sample_idx][\"prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276ba854",
   "metadata": {},
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2cfee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_LORA = False\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"student_model\",\n",
    "    max_length=256,\n",
    "    assistant_only_loss=True,\n",
    "    per_device_train_batch_size=8, \n",
    "    gradient_accumulation_steps=1,\n",
    "    remove_unused_columns=False,\n",
    "    learning_rate=1e-5,\n",
    "    eval_strategy=\"steps\",\n",
    "    num_train_epochs=3\n",
    "\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    peft_config=lora_config if USE_LORA else None\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa32981",
   "metadata": {},
   "source": [
    "### After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fa7398",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_from_prompt(test_dataset[test_sample_idx][\"prompt\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
